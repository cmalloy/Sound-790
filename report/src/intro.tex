This project aims to augment the existing geometric sound propagation and rendering pipeline with perceptually guided path sampling using feedback from auralization. The goal of our method is to enable the generation of paths that better focus computational resources on the perceptually salient regions of an audio (aural/sound) scene, while maintaining the high (same) level of perceptual quality and computationally efficient of existing systems such as gSound.Sound simulation is an important area of research with applications that heavily depend on real-time interactivity and plausible results. Interactive sound simulation is used in many fields (games, VR, architectural acoustics), however the impulse response computation for overly complex scenes results in the propagation and mixing of many paths that may not necessarily have a significant perceptual effect on the final audio. Wave based sound propagation methods can produce accurate results \cite{waves}, but take too much time to be considered for real-time applications. Geometry based methods, on the other hand, provide fast, but approximate solution to the wave equation. The accuracy of geometric (ray-based) approaches can be improved by shooting (generating) more rays (paths), however this directly correlates with the computation time of the simulation. The core idea of our project is to exploit the perceptual limitations of the human auditory system to concentrate the sampling of paths in the directions where they will be most perceptually salient.%[Small intro on perceptual part ...] It is reasonable to use this psychoacoustic principles to guide the propagation system during ray sampling phase.Psychoacoustic models such as those defined in the MPEG standard have been used extensively in the compression of digital audio.Also, Tsingos et al has previously leveraged psychoacoustic principles such as ours to prioritize the rendering of numerous sound sources in complex scenes, but their method does use psychoacoustic principles to guide the actualy impulse response calculation.We introduce a combination of techniques that improve the running time or/and perceptual quality of the sound propagation system. We first compute perceptual loudness corresponding to the sound signal and the impulse response (IR) of each path from the listener to the sound source. We next use the directional information of the paths to generate spherical distribution of a loudness around the listener, which, combined with HRTF, characterizes how an ear receives a sound from a point in space. Then we compute salience as a measure of loudness above the threshold of hearing in the presence of maskers. Finally  we integrate the salience distribution into the next frame's sampling strategy.Concretely, following are the contributions of our project work:\begin{itemize}\item a novel approach of using the psychoacoustic principles during the sound propagation stage;\item a new technique for constructing loudness distribution map;\item a partial preprocessing of the perceptual information for maintain real-time level of computations. \item an implementation the proposed methods and integration of them into gSound, an interactive sound propagation and rendering system.\end{itemize}% \subsection{Goal}% Investigate perceptually-based optimizations of path-based sound propagation and rendering, particularly by using information available during the auralization and rendering phase.% Exploit perceptual limitations of the human auditory system. Compression due to removal of perceptually irrelevant part of the signal. Results in inaudiable distortion.% The human auditory system's inability to to hear quantization noise under condition of auditory masking.